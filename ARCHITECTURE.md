# ğŸ—ï¸ Architecture

## System Overview

```mermaid
flowchart TD
    A[Aerial Imagery] --> B[Feature Extraction]
    B --> C[8 Terrain Features]
    C --> D[Feature Engineering]
    D --> E[12 Enhanced Features]
    E --> F[Ensemble Model]
    F --> G{Safety Probability}
    G -->|P >= 0.85| H[âœ… LAND]
    G -->|0.60 <= P < 0.85| I[âš ï¸ CAUTION]
    G -->|0.40 <= P < 0.60| J[ğŸ”„ LOITER]
    G -->|P < 0.40| K[âŒ ABORT]
```

## Pipeline Components

### 1. Data Ingestion
```
Landing Zone Dataset.xlsx
    â†“
pandas.read_excel()
    â†“
Data Cleaning (numeric coercion, dropna)
    â†“
3,000 clean samples
```

### 2. Feature Engineering

| Original (8) | Engineered (4) |
|--------------|----------------|
| slope_deg | slope_roughness = slope Ã— roughness |
| roughness | terrain_complexity = edge Ã— object |
| edge_density | safety_index = confidence / (slope + 1) |
| ndvi_mean | vegetation_shadow = ndvi Ã— shadow |
| shadow_fraction | |
| brightness_std | |
| object_density | |
| confidence_score | |

### 3. Model Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           VOTING ENSEMBLE               â”‚
â”‚         (Soft Voting)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Tuned    â”‚  â”‚ Stacking  â”‚  â”‚ RF  â”‚ â”‚
â”‚  â”‚  XGBoost  â”‚  â”‚ Ensemble  â”‚  â”‚     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”˜ â”‚
â”‚        â”‚              â”‚            â”‚    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                   â†“                     â”‚
â”‚           Average Probabilities         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Stacking Ensemble Internal:**
```
Base Estimators:
â”œâ”€â”€ Random Forest (n=150, depth=10)
â”œâ”€â”€ XGBoost (n=150, depth=7, lr=0.1)
â””â”€â”€ Gradient Boosting (n=150, depth=5)
        â†“
Meta-Learner: Logistic Regression
```

### 4. Training Pipeline

```mermaid
flowchart LR
    A[Raw Data] --> B[Train/Test Split 80/20]
    B --> C[SMOTE Oversampling]
    C --> D[Hyperparameter Tuning]
    D --> E[Stacking Ensemble]
    E --> F[Voting Ensemble]
    F --> G[Final Model]
```

### 5. Evaluation Metrics

```
                    Predicted
                 Unsafe    Safe
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Actual Unsafe â”‚   TN    â”‚   FP*   â”‚ â† Minimize FP (crashes)
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Actual Safe   â”‚   FN    â”‚   TP    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

* False Positive = DANGEROUS (Unsafe called Safe)
```

## Data Flow

```
1. Input: [slope, roughness, edge, ndvi, shadow, brightness, object, confidence]
                                    â†“
2. Feature Engineering: + [slope_roughness, terrain_complexity, safety_index, vegetation_shadow]
                                    â†“
3. Model Prediction: VotingClassifier.predict_proba()
                                    â†“
4. Output: Safety Probability [0.0 - 1.0]
                                    â†“
5. Decision: Apply threshold logic â†’ [LAND, CAUTION, LOITER, ABORT]
```

## Spatial Analysis

```
         Roughness
    0.0           1.0
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” 0Â°
    â”‚ ğŸŸ¢ SAFE       â”‚
    â”‚               â”‚
    â”‚    ğŸŸ¡        â”‚
  S â”‚    CAUTION   â”‚
  l â”‚               â”‚
  o â”‚        ğŸ”´    â”‚
  p â”‚     RESTRICT â”‚
  e â”‚               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ 45Â°
```

## Technology Stack

| Component | Technology |
|-----------|------------|
| Language | Python 3.8+ |
| ML Framework | scikit-learn, XGBoost |
| Data Processing | pandas, numpy |
| Visualization | matplotlib, seaborn |
| Interpretability | SHAP |
| Oversampling | imbalanced-learn (SMOTE) |
| Notebook | Jupyter |

## Performance Benchmarks

| Model | ROC-AUC | Training Time |
|-------|---------|---------------|
| Random Forest | ~0.95 | ~5s |
| XGBoost | ~0.96 | ~8s |
| Stacking | ~0.97 | ~45s |
| Voting (Final) | ~0.97 | ~60s |
